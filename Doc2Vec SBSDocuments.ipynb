{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carla\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing \n",
    "import gensim\n",
    "import nltk\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient('localhost', 27017)\n",
    "\n",
    "bdtesis = client.BDTesis\n",
    "documents2train = bdtesis.documents2train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a minusculas\n",
    "data = []\n",
    "for x in bdtesis.documents2train.find():\n",
    "    data.append(x['documento'])\n",
    "datamin =[]\n",
    "for x in (data):\n",
    "    datamin.append(x.lower()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpieza de puntuación\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "string.punctuation\n",
    "datapunc = []\n",
    "for x in datamin:\n",
    "    datapunc.append(x.translate(str.maketrans('', '', string.punctuation)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retirar stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words('spanish')\n",
    "dataclean = []\n",
    "for x in datapunc:\n",
    "    palabras = x.split()\n",
    "    resultwords  = [palabra for palabra in palabras if palabra.lower() not in stops]\n",
    "    dataclean.append(' '.join(resultwords))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(dataclean)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETROS\n",
    "cores = multiprocessing.cpu_count()\n",
    "words = 1\n",
    "size = 300\n",
    "context_window = 8\n",
    "min_count = 19\n",
    "epochs = 10\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carla\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "vec_size = 100\n",
    "alpha = 0.025\n",
    "model = Doc2Vec(size=vec_size, alpha=alpha,min_count=1, dm =0)\n",
    "model.build_vocab(tagged_data)\n",
    "%time model.train(tagged_data, total_examples=model.corpus_count, epochs=n_epochs)\n",
    "\n",
    "\n",
    "model.save(\"./doc2vec_sbs_documents_pvdbow\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec.load(\"./doc2vec_sbs_documents_pvdbow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carla\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cruzando', 0.3485018312931061),\n",
       " ('servirán', 0.31587108969688416),\n",
       " ('informados', 0.3111146092414856),\n",
       " ('fortuita', 0.30397242307662964),\n",
       " ('certifique', 0.3035879135131836),\n",
       " ('mínimas', 0.29421505331993103),\n",
       " ('combustibles', 0.2921939790248871),\n",
       " ('asalto', 0.28951817750930786),\n",
       " ('dieciocho', 0.28767311573028564),\n",
       " ('garantías', 0.28551140427589417)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['seguros'],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
