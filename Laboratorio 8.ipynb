{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el presente laboratorio se abordarán técnicas de Procesamiento de Lenguaje Natural con el fin de crear modelos de clasificación de texto. Para ello se utilizará un dataset de noticias extraídas de diversas páginas web entre Marzo y Agosto del 2014. Las categorías de noticias incluyen negocios, ciencia y tecnología, entretenimiento y salud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/machine-learning-databases/00359/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contenido\n",
    "Del repositorio del dataset se tiene la siguiente información sobre sus atributos:\n",
    "- **ID** : the numeric ID of the article\n",
    "- **TITLE** : the headline of the article\n",
    "- **URL** : the URL of the article\n",
    "- **PUBLISHER** : the publisher of the article\n",
    "- **CATEGORY** : the category of the news item; one of: -- b : business -- t : science and technology -- e : entertainment -- m : health\n",
    "- **STORY** : alphanumeric ID of the news story that the article discusses\n",
    "- **HOSTNAME** : hostname where the article was posted\n",
    "- **TIMESTAMP** : approximate timestamp of the article's publication, given in Unix time (seconds since midnight on Jan 1, 1970)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Para el desarrollo del laboratorio se puede hacer uso del módulo stopwords de la liberia nltk, para ello se puede utilizar el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ntlk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f71eb67da881>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mntlk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stopwords'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ntlk' is not defined"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "ntlk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Para realizar la lematización, se requiere instalar la base de datos de WordNet, para lo cual puede utilizar el siguiente comando\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Además, se puede consultar en el siguiente link para las tareas de Lemmatization, Stemming y expresiones regulares http://www.nltk.org/book/ch03.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploración (1p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Descargue y cargue el dataset. Identifique la cantidad de noticias por cada categoría (1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocesamiento (9p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Considere solo los títulos de los artículos para clasificar las noticias. Remueva las otras columnas del dataset (1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b1. Explore los títulos de los artículos del dataset y describa qué caracteres de puntuación (u otros caracteres) considera que deben ser removidos (0.5p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b2. Elimine dichos caracteres del dataset utilizando expresiones regulares (1.5p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Convierta el texto del dataset a minúsculas (0.5p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Remueva stopwords del texto del dataset e indique la cantidad de stopwords que está removiendo (1.5p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Genere dos versiones o copias del dataset (*data_stem* y *data_lem*):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### e1. Sobre la primera copia (data_stem), aplique Stemming (2p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### e2. Sobre la segunda copia (data_lem), aplique Lemmatization (2p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vectorización del texto (4p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Para cada copia del dataset (*data_stem* y *data_lem*) convierta el texto del título de las noticias a vectores de características utlizando CountVectorizer y TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\* Las clases CountVectorizer y TfidfVectorizer se encuentran en la librería scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a1. Vectorización de data_stem utilizando CountVectorizer (X1) (1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a2. Vectorización de data_stem utilizando TfidfVectorizer (X2) (1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a3. Vectorización de data_lem utilizando CountVectorizer (X3) (1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a4. Vectorización de data_lem utilizando TfidfVectorizer (X4) (1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento de modelos de aprendizaje de máquina (7p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Realice un train test split de cada dataset (X1,X2, X3, X4), considerando un tamaño de conjunto de prueba de 20% (1p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asegúrese de realizar la misma partición para cada dataset, para que los resultados sean comparables (i.e. si utiliza la función *train_test_split()* fije el parámetro *random_state* con el mismo valor para X1, X2, X3 y X4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Entrene por lo menos tres modelos de aprendizaje de máquina con cada conjunto de entrenamiento (X1_train, X2_train, X3_train, X4_train) utilizando validación cruzada con 5 iteraciones (folds) (3p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\* Si el tiempo de entrenamiento del modelo es demasiado alto, considere generar vectores de características más pequeños modificando el parámetro __max features__ tanto de CountVectorizer como de TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Presente una tabla con los 12 resultados de entrenamiento de cada modelo (3) con cada dataset (4) con los siguientes campos (1p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modelo utilizado\n",
    "- Dataset utlizado\n",
    "- Media de accuracy de las iteraciones de la validación cruzada\n",
    "- Desviación estándar de las iteraciones de la validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Seleccione los 3 mejores resultados y para cada uno, realice la predicción sobre el conjunto de prueba respectivo (X1_test, X2_test, X3_test o X4_test según corresponda), y reporte el accuracy obtenido y la matriz de confusión de las predicciones (2p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
